{\rtf1\ansi\ansicpg1252\cocoartf1348\cocoasubrtf170
{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
\margl1440\margr1440\vieww24220\viewh18760\viewkind0
\deftab720
\pard\pardeftab720

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 How to leverage Apache Zeppelin with Apache Spark for interactive visualization of vulnerability scan data.\
\
\
BeyondTrust - Retina Vulnerability Scanner\
Qualys - Vulnerability Scanner\
\
======\
\
Getting Started\
=======\
\
For this example I built Apache Zeppelin from source on Ubuntu Server 14.04.5 LTS with the following profiles Spark 2.0 (Apache Spark 2.0.1), Scala 2.11, and Hadoop 2.6.\
\
* [Apache Zeppelin] (https://github.com/apache/zeppelin)\
\
Next, we'll convert the vulnerabilty scan data (Qualys/Retina) from XML to JSON.  Depending on the size of your scan data you may need to \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 set the minimum (-Xms) and maximum (-Xmx) memory allocation for the JVM \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 when running **SecOps.jar**.  Also provided are perl scripts that will cut the scan data down to a manageable size.\
\
 \
```\
java -jar SecOps.jar qj <Path to Scan File>\
\
The output will result in a single JSON object for each Asset Scanned.\
\
\{"ip":"100.153.22.212","host":"tx2winweb01\'94,\'94os\'94:\'94Windows Server 2008\'94,\'94vuln\'94: [\{"id":"70000","desc":"NetBIOS Name Accessible","sev":"2"\},\{"id":"38170","desc":"SSL Certificate - Subject Common Name Does Not Match Server FQDN","sev":"2"\},\{"id":"38173","desc":"SSL Certificate - Signature Verification Failed Vulnerability","sev":"2"\},\{"id":"38601","desc":"SSL/TLS use of weak RC4 cipher","sev":"1","cve":["CVE-2013-2566"]\},\{"id":"90882","desc":"Windows Remote Desktop Protocol Weak Encryption Method Allowed","sev":"3"\}]\}\
\
```\
\
=========\
\
Load Our Data\
\
=========\
\
```\
import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\
import org.apache.spark.sql.Encoder\
import org.apache.spark.sql.Row\
import org.apache.spark.sql.types._\
import spark.implicits._\
\
/** Scan Data */\
\
val qf = spark.read.json("/tmp/qualys2.json")\
val sev = qf.withColumn(\'93vuln\'94, explode($\'94vuln\'94))\
sev.distinct().createOrReplaceTempView(\'93qualys\'94)\
\
\
```\
===========\
Number of severities by OS\
===========\
\
![alt text] (./images/num_of_sev_os.png)\
\
===========\
Top vulnerabilities\
===========\
\
![alt text] (./images/top_three_vuln.png)\
\
===========\
Servers with the most vulnerabilities\
===========\
\
![alt text] (./images/hosts_most_sev.png)\
\
===========\
Number of severities by security level\
===========\
\
![alt text] (./images/num_of_sev_level.png) \
\
===========\
Top CVEs by count\
===========\
\
\pard\pardeftab720
\cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 ![alt text] (./images/top_cve_by_count.png) \
}